{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms, models\n",
    "from  torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "# from CenterLoss import CenterLoss\n",
    "from torch.autograd.function import Function\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2020\n",
    "EPOCH = 50\n",
    "IMG_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, n_channels=1, is_train=True, transforms=None):\n",
    "        self.data = df.iloc[:, 1:].values\n",
    "#         self.fnames = df['image_id'].values\n",
    "        self.n_channels = n_channels\n",
    "        self.labels = df['label'].values\n",
    "        self.transforms = transforms\n",
    "        self.is_train = is_train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx, :].reshape(IMG_SIZE, IMG_SIZE).astype(np.uint8)\n",
    "        image = (image*(255.0/image.max())).astype(np.uint8)\n",
    "        \n",
    "        if self.transforms:\n",
    "            if self.transforms.albumentations:\n",
    "                aug = Augmentation().get_augmentation(self.transforms.albumentations)\n",
    "                augmented = aug(image=image)\n",
    "                image = augmented['image'].astype(np.float32)\n",
    "\n",
    "        image = image.reshape(1, IMG_SIZE, IMG_SIZE).astype(np.float32)\n",
    "        if self.n_channels > 1:\n",
    "            image = np.concatenate([image for i in range(self.n_channels)], axis=0)\n",
    "\n",
    "        if self.is_train:\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folds = pd.DataFrame(index=train_df.index.values)\n",
    "folds['fold_0'] = 0\n",
    "\n",
    "fold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "for fold_, (trn_idx, val_idx) in enumerate(fold.split(train_df)):\n",
    "    folds.loc[val_idx, f'fold_{fold_}'] = 0.2\n",
    "    folds.loc[trn_idx, f'fold_{fold_}'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_num = 0\n",
    "x_trn = train_df[folds[f'fold_{fold_num}'] > 0]\n",
    "x_val = train_df[folds[f'fold_{fold_num}'] == 0]\n",
    "\n",
    "y_val = x_val['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MnistDataset(x_trn, n_channels=1, transforms=None)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "valid_dataset = MnistDataset(x_val, n_channels=1, transforms=None)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = models.resnet18().to(device)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False).to(device)\n",
    "model.fc = nn.Linear(in_features=512, out_features=NUM_CLASSES, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "sheduler = lr_scheduler.StepLR(optimizer, 20, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1 - avg_train_loss: 0.9010  avg_val_loss: 0.2769 val_score: 0.9210 time: 3s<p>Epoch 2 - avg_train_loss: 0.1750  avg_val_loss: 0.1947 val_score: 0.9416 time: 3s<p>Epoch 3 - avg_train_loss: 0.0837  avg_val_loss: 0.1585 val_score: 0.9513 time: 3s<p>Epoch 4 - avg_train_loss: 0.0465  avg_val_loss: 0.1461 val_score: 0.9542 time: 3s<p>Epoch 5 - avg_train_loss: 0.0284  avg_val_loss: 0.1368 val_score: 0.9571 time: 3s<p>Epoch 6 - avg_train_loss: 0.0207  avg_val_loss: 0.1331 val_score: 0.9578 time: 3s<p>Epoch 7 - avg_train_loss: 0.0152  avg_val_loss: 0.1311 val_score: 0.9586 time: 3s<p>Epoch 8 - avg_train_loss: 0.0114  avg_val_loss: 0.1274 val_score: 0.9601 time: 3s<p>Epoch 9 - avg_train_loss: 0.0087  avg_val_loss: 0.1260 val_score: 0.9602 time: 3s<p>Epoch 10 - avg_train_loss: 0.0079  avg_val_loss: 0.1251 val_score: 0.9603 time: 3s<p>Epoch 11 - avg_train_loss: 0.0065  avg_val_loss: 0.1243 val_score: 0.9604 time: 3s<p>Epoch 12 - avg_train_loss: 0.0057  avg_val_loss: 0.1233 val_score: 0.9616 time: 3s<p>Epoch 13 - avg_train_loss: 0.0049  avg_val_loss: 0.1230 val_score: 0.9616 time: 3s<p>Epoch 14 - avg_train_loss: 0.0041  avg_val_loss: 0.1215 val_score: 0.9617 time: 3s<p>Epoch 15 - avg_train_loss: 0.0040  avg_val_loss: 0.1226 val_score: 0.9619 time: 3s<p>Epoch 16 - avg_train_loss: 0.0038  avg_val_loss: 0.1215 val_score: 0.9620 time: 3s<p>Epoch 17 - avg_train_loss: 0.0034  avg_val_loss: 0.1215 val_score: 0.9621 time: 3s<p>Epoch 18 - avg_train_loss: 0.0031  avg_val_loss: 0.1215 val_score: 0.9621 time: 3s<p>Epoch 19 - avg_train_loss: 0.0029  avg_val_loss: 0.1213 val_score: 0.9628 time: 3s<p>Epoch 20 - avg_train_loss: 0.0028  avg_val_loss: 0.1211 val_score: 0.9628 time: 3s<p>Epoch 21 - avg_train_loss: 0.0026  avg_val_loss: 0.1202 val_score: 0.9629 time: 3s<p>Epoch 22 - avg_train_loss: 0.0023  avg_val_loss: 0.1205 val_score: 0.9628 time: 3s<p>Epoch 23 - avg_train_loss: 0.0022  avg_val_loss: 0.1197 val_score: 0.9634 time: 3s<p>Epoch 24 - avg_train_loss: 0.0021  avg_val_loss: 0.1207 val_score: 0.9632 time: 3s<p>Epoch 25 - avg_train_loss: 0.0020  avg_val_loss: 0.1201 val_score: 0.9633 time: 3s<p>Epoch 26 - avg_train_loss: 0.0019  avg_val_loss: 0.1205 val_score: 0.9634 time: 3s<p>Epoch 27 - avg_train_loss: 0.0018  avg_val_loss: 0.1193 val_score: 0.9637 time: 3s<p>Epoch 28 - avg_train_loss: 0.0019  avg_val_loss: 0.1200 val_score: 0.9634 time: 3s<p>Epoch 29 - avg_train_loss: 0.0017  avg_val_loss: 0.1194 val_score: 0.9640 time: 3s<p>Epoch 30 - avg_train_loss: 0.0016  avg_val_loss: 0.1199 val_score: 0.9636 time: 3s<p>Epoch 31 - avg_train_loss: 0.0015  avg_val_loss: 0.1194 val_score: 0.9637 time: 3s<p>Epoch 32 - avg_train_loss: 0.0015  avg_val_loss: 0.1192 val_score: 0.9640 time: 3s<p>Epoch 33 - avg_train_loss: 0.0015  avg_val_loss: 0.1199 val_score: 0.9637 time: 3s<p>Epoch 34 - avg_train_loss: 0.0015  avg_val_loss: 0.1191 val_score: 0.9636 time: 3s<p>Epoch 35 - avg_train_loss: 0.0013  avg_val_loss: 0.1198 val_score: 0.9640 time: 3s<p>Epoch 36 - avg_train_loss: 0.0013  avg_val_loss: 0.1197 val_score: 0.9638 time: 3s<p>Epoch 37 - avg_train_loss: 0.0012  avg_val_loss: 0.1194 val_score: 0.9638 time: 3s<p>Epoch 38 - avg_train_loss: 0.0012  avg_val_loss: 0.1184 val_score: 0.9641 time: 3s<p>Epoch 39 - avg_train_loss: 0.0013  avg_val_loss: 0.1190 val_score: 0.9642 time: 3s<p>Epoch 40 - avg_train_loss: 0.0012  avg_val_loss: 0.1187 val_score: 0.9648 time: 3s<p>Epoch 41 - avg_train_loss: 0.0012  avg_val_loss: 0.1180 val_score: 0.9649 time: 3s<p>Epoch 42 - avg_train_loss: 0.0011  avg_val_loss: 0.1189 val_score: 0.9644 time: 3s<p>Epoch 43 - avg_train_loss: 0.0011  avg_val_loss: 0.1189 val_score: 0.9646 time: 3s<p>Epoch 44 - avg_train_loss: 0.0011  avg_val_loss: 0.1198 val_score: 0.9638 time: 3s<p>Epoch 45 - avg_train_loss: 0.0010  avg_val_loss: 0.1186 val_score: 0.9646 time: 3s<p>Epoch 46 - avg_train_loss: 0.0010  avg_val_loss: 0.1183 val_score: 0.9648 time: 3s<p>Epoch 47 - avg_train_loss: 0.0010  avg_val_loss: 0.1186 val_score: 0.9645 time: 3s<p>Epoch 48 - avg_train_loss: 0.0010  avg_val_loss: 0.1184 val_score: 0.9647 time: 3s<p>Epoch 49 - avg_train_loss: 0.0010  avg_val_loss: 0.1185 val_score: 0.9649 time: 3s<p>Epoch 50 - avg_train_loss: 0.0008  avg_val_loss: 0.1185 val_score: 0.9646 time: 3s"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "CV: 0.9648957761190491\n",
      "\n",
      "BEST EPOCH: 41\n",
      "BEST RECALL: 0.9648957761190491\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_epoch = -1\n",
    "best_val_score = -np.inf\n",
    "mb = master_bar(range(EPOCH))\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "val_score_list = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for epoch in mb:\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "\n",
    "    for images, labels in progress_bar(train_loader, parent=mb):\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        \n",
    "        preds = model(images.float())\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "    train_loss_list.append(avg_loss)\n",
    "\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    valid_preds = np.zeros((len(valid_loader.dataset), NUM_CLASSES))\n",
    "    avg_val_loss = 0.\n",
    "\n",
    "    for i, (images, labels) in enumerate(valid_loader):\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        preds = model(images.float())\n",
    "\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        valid_preds[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] = preds.cpu().detach().numpy()\n",
    "        avg_val_loss += loss.item() / len(valid_loader)\n",
    "\n",
    "    val_score = recall_score(y_val, np.argmax(valid_preds, axis=1), average='macro')\n",
    "\n",
    "    val_loss_list.append(avg_val_loss)\n",
    "    val_score_list.append(val_score)\n",
    "        \n",
    "    elapsed = time.time() - start_time\n",
    "    mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f} val_score: {val_score:.4f} time: {elapsed:.0f}s')\n",
    "\n",
    "    if best_val_score < val_score:\n",
    "        best_epoch = epoch + 1\n",
    "        best_val_score = val_score\n",
    "        best_valid_preds = valid_preds\n",
    "        best_model = model.state_dict()\n",
    "        counter = 0\n",
    "        \n",
    "    counter += 1\n",
    "    if counter == 100:\n",
    "        break\n",
    "\n",
    "print('\\n\\n===================================\\n')\n",
    "print(f'CV: {best_val_score}\\n')\n",
    "print(f'BEST EPOCH: {best_epoch}')\n",
    "print(f'BEST RECALL: {best_val_score}')\n",
    "print('\\n===================================\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
